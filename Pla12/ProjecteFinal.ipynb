{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projecte final de curs\n",
    "\n",
    "## Detecció de cares i reconeixement de persones\n",
    "\n",
    "Com a part final del curs de tècnic de visió per computador, es demana crear un algoritme capaç de detectar cares en una fotografia i reconèixer si les cares detectades pertanyen a algun dels alumnes del curs\n",
    "\n",
    "Es crearà un dataset comú per a tots els alumnes del curs. El dataset es dividirà en tres parts: entrenament, validació i test. Es demana: \n",
    "\n",
    "- Avaluació de l'algoritme en el conjunt de test per a la tasca de detecció de cares\n",
    "- Avaluació de l'algoritme en el conjunt de test per a la tasca de reconeixement d'alumnes\n",
    "- Avaluació de la velocitat dels algoritmes en fer inferència\n",
    "\n",
    "L'entrega del projecte es realitzarà fent una presentació d'uns 10 minuts, explicant la metodologia seguida i comentant els resultats\n",
    "\n",
    "No hi ha limitacions en quant a l'algoritme a presentar. També es poden fer servir datasets externs per tal de millorar el rendiment dels detectors i classificadors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Cada alumne proporcionarà una trentena de fotografies on aparegui la seva cara. Les fotografies hauran d'estar etiquetades amb regions rectangulars mitjançant el software http://www.robots.ox.ac.uk/~vgg/software/via/\n",
    "\n",
    "La mida de les imatges no pot ser superior a 1024 píxels (pel costat més llarg)\n",
    "\n",
    "Per a facilitar el dataset, es demanen fotografies similars a aquesta:\n",
    "\n",
    "<img src='./Imatges/Exemple_imatges.png'>\n",
    "\n",
    "També es demanen fotografies on aparegui l'alumne rodejat d'altres persones.\n",
    "\n",
    "<b>Etiquetatge:</b>\n",
    "\n",
    "Cada alumne etiquetarà les seves imatges i el professorat crearà un projecte fusionant tots els etiquetats.\n",
    "\n",
    "El software per etiquetatge serà  http://www.robots.ox.ac.uk/~vgg/software/via/\n",
    "\n",
    "Es demana etiquetar el rectangle de la cara i també la posició dels ulls, el nas i la boca\n",
    "\n",
    "Cada regió tindrà activa la propietat nom, que té per valors:\n",
    "\n",
    "- Nom de la l'alumne (per a la regió rectangular). Si és una persona no alumne, es posarà l'etiqueta 'Desconegut'\n",
    "\n",
    "- Nom del facial landmark (en cas contrari)\n",
    "\n",
    "<img src='./Imatges/ricard_etiquetat.png'>\n",
    "\n",
    "\n",
    "\n",
    "S'haurà de construir un dataloader amb pytorch per tal de llegir el format generat per l'aplicatiu d'etiquetatge\n",
    "\n",
    "\n",
    "## Fer fotos de grup!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets relacionats\n",
    "\n",
    "## Labeled faces in the wild\n",
    "\n",
    "http://vis-www.cs.umass.edu/lfw/index.html\n",
    "\n",
    "Dataset per a verificació de cares, és a dir, donada una parella d'imatges amb cares, dir si són la mateixa persona o no. Conté 13000 imatges de 5700 persones, capturades amb un detector tipus Viola Jones amb imatges disponibles a Internet.\n",
    "\n",
    "<b>Rendiment humà: </b> 99.2%\n",
    "\n",
    "Fent servir Amazon Data Turk\n",
    "\n",
    "<b>Rendiment sistema comercial:</b> 99.88% \n",
    "\n",
    "[Innovative technology](https://www.innovative-technology.com/icu), fa servir deep learning i un dataset propi de 5M imatges\n",
    "\n",
    "\n",
    "\n",
    "<img src='./Imatges/LFW_human.png'>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Altres datasets, mètodes i informació sobre reconeixement de cares\n",
    "\n",
    "http://www.face-rec.org/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consells pràctics per a fer aprenentatges\n",
    "\n",
    "* Fer servir transfer learning quan sigui possible\n",
    "* Test dataloaders, tant en validació com en train\n",
    "* Començar amb un dataset molt petit (1 o 2 imatges), hauria d'aparèixer overfitting\n",
    "* Després de validació, desar l'estat actual en cas que l'error de validació sigui mínim:\n",
    "\n",
    "```python\n",
    "    if is_best:\n",
    "                torch.save({'epoch': epoch + 1,\n",
    "                            'state_dict': model.state_dict(),\n",
    "                            'best_MAE': best_MAE,\n",
    "                            'optimizer': optimizer.state_dict(),\n",
    "                            'scheduler': scheduler.state_dict(),\n",
    "                        }, 'checkpoint.pth.tar')\n",
    "\n",
    "```         \n",
    "* Preparar algoritme de train per a poder continuar a partir d'aquests models desats\n",
    "* Preparar algoritme de train per a que accepti tots els paràmetres per fitxer de text:\n",
    "\n",
    "```\n",
    "[net]\n",
    "# Testing\n",
    "batch=1\n",
    "subdivisions=1\n",
    "# Training\n",
    "# batch=64\n",
    "# subdivisions=2\n",
    "width=416\n",
    "height=416\n",
    "channels=3\n",
    "momentum=0.9\n",
    "decay=0.0005\n",
    "angle=0\n",
    "saturation = 1.5\n",
    "exposure = 1.5\n",
    "hue=.1\n",
    "..\n",
    "```\n",
    "* Aplicar data augmentation en cas de detectar overfitting\n",
    "* Començar amb learning rate alt i anar baixant a mesura que l'error s'estabilitza\n",
    "* Planificar bé les proves, és fàcil perdre el fil\n",
    "* Balançejar bé les classes d'aprenentatge\n",
    "* Si fem regressió, intentar convertir a classificació\n",
    "\n",
    "### Tensorboard\n",
    "\n",
    "<img src='Imatges/tensorboard.png'>\n",
    "\n",
    "* Permet visualitzar com va l'aprenentatge\n",
    "* Permet mostrar escalars al llarg de les iteracions, però també imatges, etc\n",
    "* Permet comparar aprenentatges entre sí\n",
    "\n",
    "<img src='Imatges/tensorboard2.png'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
