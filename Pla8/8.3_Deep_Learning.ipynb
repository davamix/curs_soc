{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.3 Deep Learning\n",
    "\n",
    "El **Deep Learning** es caracteritza per ser un aprenentatge profund on el processament de les dades es fa de forma *jeràrquica*, a través de **xarxes neuronals**, amb múltiples capes de neurones connectades entre sí que van obtenint representacions cada cop més complexes i abstractes de les dades.\n",
    "\n",
    "Seguint l'exemple de [Margaret Rouse](https://searchdatacenter.techtarget.com/es/definicion/Aprendizaje-profundo-deep-learning), podríem comparar el procés d'aprenentatge del deep learning amb el procés amb què els humans aprenem les abstraccions des que som nens. Quan un nen petit aprèn una nova paraula nova, per exemple \"gos\", normalment passa una fase on va assenyalant diferents objectes mentre repeteix la paraula \"gos\" i l'adult el va corregint o reafirmant en la seva selecció (\"no, això no és un gos\", o bé, \"sí, és un gos\"), el nen va adonant-se en cada repetició (en cada iteració) de les característiques que té un gos, va creant una abstracció més complexa (el concepte de gos) i construint una jerarquia en la qual cada nivell d'abstracció es crea amb el coneixement que va obtenir de la capa precedent en la jerarquia.\n",
    "\n",
    "En el deep learning el procés és similar: cada capa aplica una transformació no lineal a l'entrada i utilitza el que aprèn per crear un model de sortida que serà l'entrada a la següent capa. I així va fent iteracions fins aconseguir un nivell de precisió acceptable. Els models acostumen a fer servir xarxes neuronals de moltes capes de profunditat, el que inspirar el nom de xarxes neuronals *profundes* o aprenentatge *profund* (en anglès *deep* learning).\n",
    "\n",
    "A més a més, un dels handicaps de la classificació de l'aprenentatge supervisat tradicional és que en gran mesura els resultats depenen de la qualitat de l'etiquetatge de les dades d'entrenament, de la seva extracció de característiques. La  majoria de vegades l'etiquetatge està fet per persones que valoren quines són les característiques principals que ha de fer servir l'algoritme per poder classificar bé les dades. Amb el deep learning, en canvi, l'extracció de característiques es fa de manera automàtica i sense supervisió, a la vegada que el sistema entrena i aprèn de de les dades. I en moltes ocasions els resultats són molt millors i precisos que amb la supervisió manual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Com va començar tot: ImageNet i AlexNet\n",
    "\n",
    "[ImageNet](http://image-net.org/index) és una gran base de dades d'imatges organitzada de forma jeràrquica segons el contingut de les imatges en unes 22.000 categories. Va ser creada arrel de la necessitat de grans bases de dades per a la recerca acadèmica i també per a fer-se servir en món de l'educació. Actualment consta de més de 14 milions d'imatges.\n",
    "\n",
    "La manera com organitza jeràrquicament les imatges es basa en la gran base de dades lèxica anglesa coneguda com [WordNet](https://wordnet.princeton.edu/). Aquesta estableix la relació entre sinònims i els agrupa sota grups anomenats *synsets*. A més, també estableix relacions de subordinació entre diferents synsets enllaçant conjunts més generals amb conjunts més específics; per exemple, \"moble\" té com a subordinat \"llit\" que a la vegada té com a subordinats \"potes\" i \"somier\". WordNet classifica tant noms com verb, però ImageNet només utilitza noms a dia d'avui. \n",
    "\n",
    "ImageNet va crear al 2010 les competicions anuals ILSVRC (de l'anglès *ImageNet Large Scale Visual Recognition Challenge*) per avaluar els algoritmes de detecció d'objectes i de classificació d'imatges a gran escala. L'objectiu era doble: per una banda es volia motivar als investigadors permetent-los comparar els seus avenços grans bases de dades i, per una altra banda, es volia mesurar el progrés de la visió per computador en la indexació d'imatges a gran escala. En els ILSVRC s'utilitza un subconjunt de l'ImageNet amb unes 1000 imatges per a cadascuna de les 1000 categories, en total aproximadament 1,2 milions d'imatges.\n",
    "\n",
    "En l'edició dels ILSVRC del 2012, l'algoritme guanyador va ser el creat per Alex Krizhevsky i va ser tota una revolució quant a encerts en els resultats.  La seva tassa d’error era més de 10 punts millor que el seu competidor més proper (15,3% vs 26,2%), i això en recerca és un salt de gegant. \n",
    "\n",
    "Resolia el problema de classificar imatges fent servir 1000 classes diferents (gats, gossos, etc.). La sortida era un vector amb 1000 elements, 1000 números. L'element n-èssim del vector sortida s'interpretava com la probabilitat que la imatge d'entrada pertanyés a la classe n-èssima. Per tant, la suma de tots els elements del vector de sortida era 1.\n",
    "\n",
    "El model de xarxa guanyadora utilitzava una millora de una CNN amb una arquitectura de 8 capes (7 d’elles ocultes); les 5 primeres eren capes convolucionals i les últimes 3 eren capes totalment connectades. Per evitar la no-linealitat va fer servir el Relu enlloc de les funcions sigmoid and tanh que es feien servir fins aleshores; i aplicava un max-pooling després de la 1a, 2a i 5a capa de convolució. La xarxa va necessitar 90 iteracions per entrenar 650.000 neurones, 60 milions de paràmetres i 630 milions de connexions.  Va trigar 6 dies a entrenar la xarxa utilitzant dos GPUs .\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td style=\"border:1px solid black; width:500px\">\n",
    "            <img src=\"Imatges/AlexNet-blocks.png\">\n",
    "        </td>\n",
    "    </tr>   \n",
    "    <tr>\n",
    "        <td style=\"border:1px solid black\" align=center>\n",
    "            Arquitectura AlexNet<br>Font: <a href=\"https://towardsdatascience.com/the-w3h-of-alexnet-vggnet-resnet-and-inception-7baaaecccc96\">Towards Data Science</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "El model va ser la primera xarxa convolucional profunda (**deep** *convolutional network*) a assolir resultats precisos i acurats. En aquell moment aquesta arquitectura era molt més complexa que les clàssiques CNN, tot i que a dia d'avui encara n'existeixen de més complexes i que, tot i així, entrenen i obtenen resultats en molt menys temps gràcies a les millores tecnològiques.\n",
    "\n",
    "Si vol saber-ne més detalls us recomanem llegir [Understanding AlexNet](https://www.learnopencv.com/understanding-alexnet/) de Sunita Nayak.\n",
    "\n",
    "L’arquitectura guanyadora del ILSVRC 2012 es va fer famosa com la xarxa **AlexNet** (pel nom del seu creador) i va representar un punt d’inflexió en el món de la visió per computador. A partir d’aquell moment molta més gent va començar a utilitzar arquitectures CNN i  es va obrir un gran ventall d’usos reals per al Deep Learning.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td style=\"border:1px solid black;\" colspan=2 align=center>\n",
    "            <img src=\"Imatges/AlexNet-exemples.jpg\">\n",
    "        </td>\n",
    "    </tr>   \n",
    "    <tr>\n",
    "        <td style=\"border:1px solid black\" width=47%>\n",
    "            Resultats de l'AlexNet: 8 imatges de prova del ILSVRC-2010 i les corresponents 5 etiquetes considerades més probables pel model AlexNet. Sota cada imatge hi ha l'etiqueta correcta. La probabilitat assignada a cada etiqueta resultat té una barra de probabilitat en el fons (de color vermell si es troba entre les 5 primeres)\n",
    "        </td>\n",
    "        <td style=\"border:1px solid black\">\n",
    "            Resultats de l'AlexNet: la primera columna conté 5 imatges de prova del ILSVRC-2010. A les altres columnes les imatges d'entrenaments que produeixen vectors de característiques a l'última capa oculta de l'AlexNet amb distància euclidiana més petita a la imatge de prova.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"border:1px solid black\" align=center colspan=2>\n",
    "            Font: <a href=\"https://neurohive.io/en/popular-networks/alexnet-imagenet-classification-with-deep-convolutional-neural-networks/\">Neurohive</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "Avui en dia la implementació d'AlexNet és molt fàcil gràcies a llibreries de deep learning com [PyTorch](https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py), [TensorFlow](https://github.com/tensorflow/models/blob/master/research/slim/nets/alexnet.py) o [Keras](https://github.com/eweill/keras-deepcv/blob/master/models/classification/alexnet.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch\n",
    "\n",
    "PyTorch és una de les llibreries més populars per implementar deep learning en Python i aprofitar el potencial de les GPUs.\n",
    "\n",
    "Per entrenar un classificador d'imatges haurem de seguir els següents passos per ordre:\n",
    "1. Carregar i normalitzar les bases de dades d'imatges d'entrenament i de validació utilitzant torchvision.\n",
    "2. Definir la xarxa neuronal convolucional a fer servir.\n",
    "3. Definir la funció de pèrdua (*loss function*)\n",
    "4. Entrenar la xarxa amb les dades d'entrenament (normalment amb valors dels pesos inicialitzats aleatòriament).\n",
    "5. Testejar la xarxa amb les dades de validació.\n",
    "\n",
    "Però molt poques vegades tenim conjunts de dades suficientment grans com per entrenar correctament una xarxa convolucional o qualsevol model de deep learning des de zero (amb inicialització aleatòria de pesos), o tampoc tenim el temps suficient per entrenar tot el model. En aquests casos és molt comú fer servir una xarxa pre-entrenada amb un conjunt de dades gran i fer-la servir com a inicialització a la nostra xarxa o directament com un extractor de característiques per les nostres dades. Aquest procés es coneix com *Transfer Learning* i en veurem un exemple pràctic en l'exemple final d'aquest capítol (per més informació sobre Transfer Learning podeu mirar [aquesta pàgina](https://cs231n.github.io/transfer-learning/)).\n",
    "\n",
    "Abans de passar a l'exemple final de deep learning, cal aclarir alguns conceptes i paràmetres que farem servir en deep learning amb PyTorch, aquests són els tensors, la funció de pèrdua i el backpropagation.\n",
    "\n",
    "#### Tensor\n",
    "Els algoritmes necessiten representar les dades en format numèric, ja hem vist que una imatge es representa internament com una matriu de números, on cada número representa el valor del color del píxel corresponent. En xarxes neuronals, a més de representar les dades d'entrada en format numèric, també necessitem aplicar uns càlculs i desar els resultats per passar-los com entrada a la següent capa. Això es realitza internament a través d'un repositori de dades que es coneix com **tensor**.\n",
    "\n",
    "Moltes vegades es confon un tensor amb una matriu, però el cert és que un tensor pot desar dades d'N dimensions, mentre que una matriu s'acostuma a utilitzar per 2 dimensions. Podríem dir que el tensor és una generalització de la matriu en un espai N-dimensional.\n",
    "\n",
    "Probablement ho entendreu millor amb la següent imatge, on podem veure la diferència entre matrius i tensors:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td style=\"border:1px solid black; width:500px\">\n",
    "            <img src=\"Imatges/scalar-vector-matrix-tensor.jpg\">\n",
    "        </td>\n",
    "    </tr>   \n",
    "    <tr>\n",
    "        <td style=\"border:1px solid black\" align=center>\n",
    "            Font: <a href=\"https://hadrienj.github.io/posts/Deep-Learning-Book-Series-2.1-Scalars-Vectors-Matrices-and-Tensors/\">https://hadrienj.github.io/</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "A més de desar dades numèriques, els tensors també poden desar descripcions de les transformacions lineals entre tensors (com per exemple el producte vectorial o el producte escalar). És per aquest motiu que hi ha autors que creuen que els tensors no sols són una estructura de dades, sinó també objectes orientats a la relació entre objectes. \n",
    "\n",
    "#### Funció de pèrdua (Loss function)\n",
    "Entrenar una xarxa neuronal implica donar unes dades al model, esperar que faci les seves prediccions, comprovar si les prediccions són correctes o no, aprendre dels errors, i repetir aquest procés fins que el model arribi a un cert nivell de precisió que decidim prèviament.\n",
    "\n",
    "Comprovar si les prediccions són correctes o no és un pas crucial per poder aprendre. I això ho fem a través de la **funció de pèrdua** o (*Loss function* en anglès). \n",
    "\n",
    "La funció de pèrdua li diu al model com de lluny (o de prop) està la seva predicció respecte al valor correcte. Per calcular-lo es poden fer servir diferents funcions matemàtiques, les més simples podrien ser la mitjana de l'error absolut, o el quadrat de l'error absolut. Però n'hi ha moltes més, si voleu veure un llistat podeu llegir [A Brief Overview of Loss Functions in Pytorch](https://medium.com/udacity-pytorch-challengers/a-brief-overview-of-loss-functions-in-pytorch-c0ddb78068f7) (de Pratyaksha Jha).\n",
    "\n",
    "#### Backpropagation\n",
    "Com ja hem introduït en seccions anteriors, el backpropagation s'utilitza per poder aprendre dels errors. A partir de la funció de pèrdua el model calcula de darrere a endavant el gradient de la funció de pèrdua respecte als pesos de la xarxa neuronal, i corregeix o ajusta aquests pesos per minimitzar l'error (el model *aprèn* dels errors).\n",
    "\n",
    "PyTorch té el paquet *Autograd* per aplicar el backpropagation i, dins d'aquest paquet, tenim les *Variables* per desar les dades que aniran variant durant el procés d'entrenament de la xarxa neuronal, és a dir, els paràmetres a aprendre com els pesos i els gradients associats a la funció de pèrdua. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referències:\n",
    "\n",
    "**AlexNet**:\n",
    " - [Understanding AlexNet](https://www.learnopencv.com/understanding-alexnet/) de Sunita Nayak.\n",
    "\n",
    " - L'article guanyador del ILSVRC 2012 (AlexNet): *ImageNet Classification with Deep Convolutional Neural Networks*, Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton: [https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\n",
    "  - Presentació AlexNet: [http://www.image-net.org/challenges/LSVRC/2012/supervision.pdf\n",
    "](http://www.image-net.org/challenges/LSVRC/2012/supervision.pdf\n",
    "\n",
    "**PyTorch**:\n",
    " - Tutorial de PyTorch en 60 minuts: [https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
    " - Documentació de PyTorch: [https://pytorch.org/docs/stable/index.html](https://pytorch.org/docs/stable/index.html)\n",
    " - Un exemple pràctic de PyTorch: *A PyTorch tutorial – deep learning in Python*: [https://adventuresinmachinelearning.com/pytorch-tutorial-deep-learning/](https://adventuresinmachinelearning.com/pytorch-tutorial-deep-learning/)\n",
    " \n",
    "**Tutorials de Deep Learning**:\n",
    " - <span style=\"color:red\">MOLT RECOMANABLE!</span> Curs *Practical Deep Learning for coders* de fast.ai: [https://course.fast.ai/videos/?lesson=1](https://course.fast.ai/videos/?lesson=1)\n",
    " - Deep Learning with Python, de François Chollet: [https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff](https://www.manning.com/books/deep-learning-with-python?a_aid=keras&a_bid=76564dff)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
