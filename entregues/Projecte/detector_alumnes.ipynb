{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from PIL import Image, ImageDraw\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from facenet_pytorch import MTCNN, extract_face\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display\n",
    "\n",
    "import torchvision.transforms.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "# seleccionar GPU si està disponible..\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model initialization and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and set to evaluation mode\n",
    "PATH = 'model_UOC.pth'\n",
    "new_model = torch.load(PATH)\n",
    "\n",
    "new_model.eval()\n",
    "new_model.to(device)\n",
    "\n",
    "enum_classes= ['DanielValcarce', 'EnriqueGraziano', 'FranciscoMartin', 'GenisHeredia', 'JordiCasals', 'MarcelSerra', 'OriolJulia', 'PereClaver', 'RicardPeralta', 'RogerRoca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the face detector\n",
    "mtcnn = MTCNN(\n",
    "        image_size=224, margin=0, min_face_size=20, \n",
    "        thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True, \n",
    "        device=device, keep_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the transformations to be applied to images\n",
    "transform = transforms.Compose([          \n",
    "            transforms.Resize(224),   #mida d'entrada de la xarxa neuronal\n",
    "            transforms.CenterCrop(224),    #important. Sinó dóna error perquè les imatges no son quadrades       \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])  #mitja i desviacio estandard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect faces on an image\n",
    "#\n",
    "# detector: instance of MTCNN detector\n",
    "# image: original image\n",
    "def detect_faces(detector, image):\n",
    "    boxes, probs, points = mtcnn.detect(image, landmarks=True)\n",
    "    \n",
    "    return boxes, probs, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classes from a face image\n",
    "#\n",
    "# model: instance of the model\n",
    "# image: face image, cropped from the original image\n",
    "# transformations: trasformations to be applied on image by the model\n",
    "\n",
    "def predict(model, image, transformations):\n",
    "    \n",
    "    # if image is already a Tensor, convert it to a PIL Image in order to apply the model transformations    \n",
    "    if isinstance(image, torch.FloatTensor):\n",
    "        #print(\"already tensor. transorm to PIL\")\n",
    "        image=image.permute(1, 2, 0).numpy().astype('uint8')\n",
    "        imagePIL= transforms.ToPILImage()(image)\n",
    "    \n",
    "          \n",
    "    # Apply the transform to the image\n",
    "    img = transformations(imagePIL) \n",
    "    img = img.to(device)\n",
    "\n",
    "    # Pass the image to the model\n",
    "    pred = model(img[None, ...])\n",
    "    _, preds = torch.max(pred, 1)\n",
    "\n",
    "    # Get probs\n",
    "    sm = torch.nn.Softmax(dim=1)\n",
    "    probs = sm(pred)\n",
    "\n",
    "    resultat= enum_classes[preds]\n",
    "    #print(resultat)\n",
    "    return pred, preds, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the original image with the face regions, classes and probabilities\n",
    "#\n",
    "# image: Original image\n",
    "# detections: Array with all bboxes, class predicted and probilities\n",
    "def show_image(image, detections):\n",
    "    img_draw = image.copy()\n",
    "    draw = ImageDraw.Draw(img_draw)\n",
    "    \n",
    "    for i, detection in enumerate(detections):\n",
    "        box = detection[0] # Array with bbox values [x, y, w, h]\n",
    "        draw.rectangle(box.tolist(), width=2)\n",
    "        if detection[2]>0.98:\n",
    "            caption = f\"{detection[1]} - {detection[2]*100:.2f}%\"\n",
    "            draw.text((box[0], box[1]-10), caption)\n",
    "        else:\n",
    "            caption = \"desconegut\"\n",
    "            draw.text((box[0], box[1]-10), caption)\n",
    "        \n",
    "    IPython.display.display(img_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a cropped face\n",
    "#\n",
    "# images: Array with cropped faces\n",
    "def show_face_detected(images):\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    for i, image in enumerate(images):\n",
    "        sub = fig.add_subplot(4, 4, i + 1)\n",
    "        sub.imshow(images[i].permute(1, 2, 0).numpy().astype('uint8'))\n",
    "        \n",
    "#show_face_detected()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image, preprocessing and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "image_path = os.path.join('data', 'original', 'img_3.jpg')\n",
    "im = Image.open(image_path)\n",
    "\n",
    "# Detect faces on images and get the regions for each face\n",
    "face_regions, _, _ = detect_faces(mtcnn, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all faces detected in the original image\n",
    "face_crops = []\n",
    "for face in face_regions:\n",
    "    crop = extract_face(im, face, image_size=224)\n",
    "    face_crops.append(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_face_detected(face_crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict image\n",
    "detections=[]\n",
    "\n",
    "# face_crops: Array with only image faces\n",
    "for i, crop in enumerate(face_crops):\n",
    "    \n",
    "#     fig = plt.figure(figsize=(10, 10))    \n",
    "#     sub = fig.add_subplot(2, 1, 1)\n",
    "#     sub.imshow(crop.permute(1, 2, 0).numpy().astype('uint8'))\n",
    "    \n",
    "    # Predict image with the cropped image\n",
    "    _, preds, probs = predict(new_model, crop, transform)\n",
    "\n",
    "    # Create the object with the region, class name and probability\n",
    "    detection = [face_regions[i], enum_classes[preds], probs[0][preds].item()]\n",
    "    detections.append(detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show image with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image with the detections\n",
    "show_image(im, detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [MTCNN](https://kpzhang93.github.io/MTCNN_face_detection_alignment/index.html) face landmark detector\n",
    "- [Facenet](https://github.com/timesler/facenet-pytorch) PyTorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
