{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 Aprenentatge supervisat\n",
    "\n",
    "## Machine Learning\n",
    "Machine Learning (o *Aprenentge Automàtic*) és una branca de la Intel·ligència Artificial que crea sistemes i aplica algoritmes per analitzar grups grans de dades amb l'objectiu d'aprendre i detectar patrons dins aquests grups de manera automàtica, sense la intervenció de persones.\n",
    "\n",
    "Aquests patrons ens permetran aconseguir objectius tan variats com la classificació automàtica, el clustering, la regressió, o identificar similituds, entre d'altres. Segons l'objectiu a assolir, i el tipus de dades a analitzar, escollirem un algoritme o un altre. \n",
    "\n",
    "Hi ha molts mètodes de machine learning, però sovint són categoritzats dins d'un d'aquests dos grans grups:\n",
    "- Aprenentatge supervisat: És aquell sistema que té algun tipus d'entrada inicial de dades tractades i etiquetades que es fan servir per aprendre. L'objectiu és poder identificar o etiquetar correctament qualsevol dada nova que arribi a partir del model que ha après.\n",
    "- Aprenentatge no supervisat: És aquell sistema que no té cap dada d'aprenentatge inicial, sinó que intenta trobar patrons amagats dins un gran grup de dades analitzant les dades directament.\n",
    "\n",
    "Anem a veure algun detall més de cada grup d'aprenentatge abans d'entrar a explicar alguns dels algoritmes més populars.\n",
    "\n",
    "### Aprenentatge Supervisat\n",
    "En un aprenentatge supervisat, el sistema té algun tipus de base de dades d'aprenentatge que, o bé  ha estat etiquetada, o bé ha estat classificada d'alguna manera. \n",
    "\n",
    "Per exemple, un grup de imatges de gossos i gats que han estat prèviament etiquetats amb les identificacions  corresponents, un grup de imatges classificades segons si contenen animals o plantes, les dades històriques del nivell de trànsit en un carrer segons l'hora del dia durant els últims 6 mesos, etc. \n",
    "\n",
    "L'algoritme, a partir d'aquestes dades d'aprenentatge o d'entrenament, pot _aprendre_ el model que hi ha darrere d'ells i fer prediccions de les etiquetes o les classificacions que correspondria a qualsevol mostra nova que no havia estat etiquetada prèviament. Per a qualsevol entrada de dada nova, el sistema intentarà donar-li una sortida \"correcta\" en forma de classificació o etiqueta. Per exemple, si li entrem una imatge d'un gos que no formava part de la base de dades d'aprenentatge, esperem que el sistema la classifiqui correctament com un gos.\n",
    "\n",
    "L'aprenentatge supervisat s'utilitza moltes vegades per **classificar** contingut (predir una categoria, com en el cas dels gats i gossos), o bé per fer **regressions numèriques** (predir un número). \n",
    "\n",
    "Alguns exemples que fan servir aprenentatge supervisat per classificar poden ser: filtre d'spam, detecció automàtica de idioma, cerca de documents similars, reconeixement de caràcters i dígits en una escriptura manual, etc.\n",
    "\n",
    "En el cas de les regressions, el sistema bàsicament prediu un número enlloc d'una categoria; per exemple, quin nivell de trànsit hi haurà en un carrer concret segons la hora del dia (faríem servir les dades històriques del nivell de trànsit en aquell carrer), quin serà el valor en borsa d'una empresa, etc. La majoria de sistemes que depenen del temps poden treure profit d'aquest sistema. La idea és bolcar totes les dades que es tenen en un gràfic i veure quina és la correlació mitja de les dades per poder predir un nou valor en un moment determinat del temps. A grans trets, direm que quan la correlació mitjana segueix una línia recta direm que estem davant una regressió lineal, mentre que si té corbes parlarem d'una regressió polinomial. És un mètode molt utilitzat en finances.\n",
    "\n",
    "Hi ha molts mètodes o algoritmes dins d'aquesta categoria, alguns dels més populars són KNN (K-Nearest Neighbours), SVM (Super Vector Machine), Arbres de decisions, Regressió logística, Naive Bayes, etc.\n",
    "\n",
    "### Aprenentage no supervisat\n",
    "En un aprenentatge no supervisat, en canvi, el sistema no té cap mena d'entrada inicial de dades etiquetades o classificades prèviament. Tampoc intenta trobar una sortida correcta, sinó que explora les dades i descriu estructures i patrons amagats en les mateixes. \n",
    "\n",
    "Per exemple, i seguint amb el mateix exemple anterior, li entraríem directament imatges de gossos i gats i esperaríem que el sistema detectés per sí sol que hi ha dos grups diferents d'animals i els agrupés en dos grups de sortida.\n",
    "\n",
    "Dins dels aprenentatges no supervisats, podem trobar algoritmes o mètodes amb objectius ben diferents com: \n",
    "- Classificar: clusterització per k-means, mean-shift, DBSCAN.\n",
    "- Reduir dimensions del problema: PCA (Principal Component Analysis), SVD (Singular Value Decomposition), LDA (Latent Dirichlet allocation), LSA (Latent Semantic Analysis).\n",
    "- Trobar associacions.\n",
    "\n",
    "<table style=\"border:1px solid black\">\n",
    "    <tr>\n",
    "        <td align=center>\n",
    "            <img src=\"Imatges/supervised_vs_unsupervised.jpg\">\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td align=center >\n",
    "            <i>Font: <a href=\"https://slideplayer.com/slide/14333666/\">Slideplayer (Introduction to Machine Learning, by Yulia Atmadjaja)</a></i>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<br>\n",
    " \n",
    " \n",
    "\n",
    "En aquest capítol ens centrarem en els mètodes i algoritmes d'aprenenentatge supervisat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcions objectiu i modelatge de les dades\n",
    "\n",
    "En l'aprenentatge supervisat busquem que l'algoritme aplicat aprengui a *modelar* les dades, això vol dir que ha de trobar una **funció objectiu** que permeti etiquetar les dades de sortida correctament. Podem dir, doncs, que l'objectiu principal és que donada una entrada $\\begin{equation}x\\end{equation}$, obtingui l'etiqueta $\\begin{equation}y\\end{equation}$; o més formalment: que aprengui la funció $\\begin{equation}F\\end{equation}$ tal que $\\begin{equation}F(x)=y\\end{equation}$.\n",
    "\n",
    "En el nostre cas la $\\begin{equation}x\\end{equation}$ són les imatges d'entrada, les imatges a tractar; mentre que la $\\begin{equation}y\\end{equation}$ poden ser diverses coses segons l'objectiu que busquem:\n",
    " - Classificació: buscarem categories (les $\\begin{equation}y\\end{equation}$ seran etiquetes de categories). Per exemple si un animal és gat o gos, classificar objectes dins una imatge, on són les cares en una imatge, etc.\n",
    " - Regressió: buscarem valors numèrics (les $\\begin{equation}y\\end{equation}$ serà la predicció d'un valor numèric). Per exemple: predir el valor a borsa d'una cartera, el consum energètic d'una casa, etc.\n",
    "\n",
    "<center>\n",
    "    <table style=\"border:1px solid black\" >\n",
    "        <tr>\n",
    "            <td align=center >\n",
    "                <img src=\"Imatges/clasificacion-vs-regresion-machine-learning.jpg\"><br>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"background:white\" align=center >\n",
    "               <img src=\"Imatges/clasificacion-vs-regresion-machine-learning-2.jpg\"><br>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td width=500>\n",
    "                Quan classifiquem busquem el grup (cluster) més proper a la mostra d'entrada.<br>\n",
    "                Quan fem regressió busquem el valor numèric sobre la correlació mitjana més proper a la mostra d'entrada.<br>\n",
    "                <i>(Font: <a href=\"http://epicalsoft.blogspot.com/2018/11/azure-machine-learning-algoritmos-de.html\">Epicalsoft.Instance.Blog </a>)</i>\n",
    "            </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</center>\n",
    "\n",
    "\n",
    "A la vegada, també hem de tenir en compte que, dins la classificació, podem buscar diferents nivells d'etiquetatge: \n",
    "- a nivell de *tota la imatge* per classificar imatges: com MNIST, o com l'exemple d'identificar gats i gossos,\n",
    "- a nivell de *finestres* de la imatge: com en el cas dels rectangles per detectar cares i,\n",
    "- a nivell de *píxel* per segmentar imatges: com hem vist en el capítol anterior, o per la conducció autònoma de vehicles.\n",
    "\n",
    "<table>\n",
    "    <tr width=550>\n",
    "        <td style=\"border:1px solid black\" align=center>\n",
    "            <h4>Nivell IMATGE</h4><br>\n",
    "            <img src=\"Imatges/classification-image-cat.png\"><br>\n",
    "            <i>Font: <a href=\"https://medium.com/@gnabr/machine-learning-c28daf3cf60a\">Medium (article \"Machine Learning\", de Branav Kumar Gnanamoorthy)</a> </i>\n",
    "        </td>\n",
    "        <td style=\"border:1px solid black\" align=center>\n",
    "            <h4>Nivell FINESTRA</h4><br>\n",
    "            <img src=\"Imatges/classification-rectangles-cares.jpeg\"><br>\n",
    "            <i>Font: <a href=\"https://www.technologyreview.com/s/535201/the-face-detection-algorithm-set-to-revolutionize-image-search/\">MIT Technology Review</a></i>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td colspan=2 style=\"border:1px solid black;background:white\" align=center>\n",
    "            <h4>Nivell PÍXEL</h4><br>\n",
    "            <img src=\"Imatges/classification-pixels-conduccio.png\"><br>\n",
    "            <i>Font: <a href=\"http://www.cvlibs.net/datasets/kitti/eval_semseg.php?benchmark=semantics2015\">The KITTI Vision Benchmark Suite</a> </i>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "    \n",
    "\n",
    "\n",
    "## Overfitting\n",
    "No totes les funcions objectius són les mateixes per a qualsevol tipus de dades, depenent de la topologia de les dades originals i de l'objectiu a assolir, funcionaran millor algunes funcions objectiu més que d'altres. Per això és important escollir bé l'algoritme o mètode d'aprenentatge a aplicar.\n",
    "\n",
    "Però no sols això, dins un mateix algoritme, moltes vegades també tenim paràmetres interns que poden fer variar molt els resultats.\n",
    "\n",
    "I, encara més, segons la qualitat de les dades d'aprenentatge i de les de validació, els resultats també ens poden variar molt.\n",
    "\n",
    "Ens podem trobar amb què les dades apreses per l'algoritme no separen prou les classes (aquest problema es coneix com **underfitting**), o bé, tot el contrari, que creen un model o una topologia tan específica a les dades que no podem fer cap mena de predicció fora d'elles. Imagineu-vos que arribem a classificar tan \"*acuradament*\" que creem una classe per cada mostra d'entrada, aquest model no ens serviria per predir la categoria d'una nova mostra. Això és el que es coneix com el problema d'**overfitting** (sobre-ajustament, o sobre-encaixament).\n",
    "\n",
    "Volem sistemes que modelin correctament les dades, que ho facin de manera prou general com per obtenir bons resultats amb noves dades que introduïm al sistema entrenant, però tampoc tan generals com perquè no puguem treure cap conclusió de les mateixes. Aquests dos extrems serien els dos problemes principals en què ens podem trobar quan apliquem aprenentatge supervisat i, com ja hem avançat, s'anomenen underfitting i overfitting.\n",
    "\n",
    "<center>\n",
    "    <table width=75% style=\"border:1px solid black\">\n",
    "        <tr>\n",
    "            <td  align=center>\n",
    "                <img src=\"Imatges/UnderOverFit.jpg\" size=50%><br>\n",
    "            </td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td  align=justify>\n",
    "                <i>\n",
    "                    Exemples gràfics de problemes d'underfitting (esquerra) i overfitting (dreta).\n",
    "                    Les imatges centrals són l'objectiu desitjat per tot aprenentatge supervisat. \n",
    "                    Font: <a href=\"https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/supervised_learning.html\">Elite data science</a><br>\n",
    "                </i>  \n",
    "            </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</center>\n",
    "\n",
    "\n",
    "La majoria de vegades que se'ns presenta un problema d'underfitting, el podem solucionar afegint més mostres d'aprenentatge per fer que el sistema pugui inferir més patrons que li permeti arribar a alguna conclusió. En canvi, pel problema de l'overfitting les causes poden ser més variades i les solucions no sempre tan senzilles. Per aquest motiu analitzarem amb més detall aquest problema.\n",
    "\n",
    "L'overfitting apareix quan un model s'adapta tan precisament als detalls i sorolls de les dades d'aprenentatge, que perd el nivell de generalització necessari per predir valors de noves mostres. Podríem que aprèn \"massa\". I això ho veiem fàcilment quan el model funciona molt bé sobre el conjunt d'entrenament però en canvi falla pel conjunt de validació.\n",
    "\n",
    "Anem a veure quines són les possibles causes i com  podem detectar si un model presenta overfitting, per així poder aplicar alguna mesura correctora sobre el model.\n",
    "\n",
    "#### Causes de l'overfitting\n",
    "\n",
    "Algunes causes que poden provocar l'overfitting són les següents:\n",
    "\n",
    "1. Model d'aprenentatge que no és prou generalista: Ens podem trobar overfitting quan utilitzem conjunts d'aprenentatge massa específics i diferents de la resta de mostres a classificar. El model normalment no generalitza bé per dades mai vistes. Seguint amb l'exemple de gats i gossos, si tenim un conjunt de dades de 10 races de gossos diferents però només fem servir tots els gossos d'una única raça per entrenar el sistema, probablement no deixarem que el sistema aprengui generalitzacions sobre el gos, només sobre la raça entrenada. És per aquest motiu que trobar l'equilibri en el conjunt de dades d'aprenentatge segons l'objectiu a assolir pel sistema és quasi igual d'important que escollir l'algoritme i la funció objectiu idònia.\n",
    "\n",
    "2. Soroll en les dades d'aprenentatge: el model aprèn de les mostres d'entrenament, i aquestes mostres porten implícit el senyal base i soroll afegit. Un bon sistema de machine learning separarà el senyal del soroll, però si les dades d'aprenentatge no són prou generalistes i equilibrades entre elles, el sistema pot acabar memoritzant el soroll enlloc d'aprendre el senyal. Per exemple, si modelem la relació entre edat i alçada dels infants per trobar els percentils de creixement, podrem crear un model de regressió que ens indiqui els valors mitjana; ara bé, si agafem com a mostra només infants fills de jugadors de bàsquet de la NBA, probablement acabarem predient valors erronis.\n",
    "3. Funcions objectiu massa complexes: Ens interessen funcions que creïn suficient nivell de generalització com per classificar correctament les mostres d'aprenentatge i que, a la vegada, ens permeti predir la classe de les noves mostres que formin part del conjunt d'aprenentatge. Si la funció objectiu és tan complexa que només té sentit aplicada a un grup d'aprenentatge concret, perdrem la generalització i no farem bones prediccions de les dades noves. \n",
    "<table style=\"border:1px solid black\">\n",
    "    <tr>\n",
    "        <td align=center width=300><img src=\"Imatges/Overfitting.png\"><br></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td align=justify width=300>\n",
    "            <i>Mentre que la línia negra s'ajusta bé a les dades, la línia verda indica un overfitting</i><br>\n",
    "            <i>Font: <a href=\"https://elitedatascience.com/overfitting-in-machine-learning\">Elite data science</a></i><br>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "4. No fer servir dades de validació: Es pot crear  overfitting si entrenem l'algoritme i testem els resultats amb exactament les mateixes mostres. Els resultats de l'algoritme seran fantàstics, però molt probablement fallarà a l'hora de predir dades noves. La millor pràctica sempre és dividir el grup d'entrenament en dos subgrups: un d'entrenament i un de test o validació, normalment amb una relació 70-30 (70% de les dades per entrenar, i 30% per testar).\n",
    "\n",
    "#### Detecció overfitting\n",
    "Un cop hem vist algunes de les possibles causes de l'overfitting, és hora de saber com detectar-lo, així podrem aplicar alguna solució que l'elimini o el minimitzi quan aparegui. Però, com podem detectar-lo?\n",
    "\n",
    "Un dels handicaps del machine learning és que no podem saber com de bo és un algoritme fins que no el testem amb dades reals. Una bona manera de detectar si funciona bé o està creant overfitting és dividint el grup d'aprenentatge en 2: un per entrenar i l'altre per testar. I que avaluem i comparem els resultats del model testant tant el grup d'aprenentatge com el grup de test. Si el model funciona quasi perfecte pel grup d'aprenentatge (per exemple 99,99% d'exactitud) però, en canvi, funciona molt malament pel grup de test (per exemple 52%), molt probablement estiguem fent overfitting del model.\n",
    "\n",
    "Una altra manera seria utilitzar inicialment l'algoritme més senzill que tinguem i avaluem els resultats. Farem servir aquests resultats com valors base i els anirem comparant amb altres algoritmes més complexes que volem aplicar. D'aquesta manera podrem avaluar si la complexitat afegida paga la pena respecte la millora en els resultats. \n",
    "\n",
    "#### Com podem combatre l'overfitting?\n",
    "Però detectar l'overfitting no és suficient, evidentment també volem combatre'l. Aquestes són algunes de les eines per fer-ho:\n",
    "\n",
    "- Una de les mesures més senzilles és la manera com partim les dades en conjunt d'aprenentatge i en conjunt de test: han d'estar ben equilibrades, tant a nivell de generalització de les dades, com a nivell del balanç entre senyal i soroll.\n",
    "- Més dades d'aprenentatge: si veiem que hem creat overfitting amb el model, a vegades el fet d'incrementar les mostres d'aprenentatge ajuda a generalitzar el model (si hem fet servir només 10 mostres d'entrenament, intentem fer-ne servir 100)\n",
    "- Validació creuada (Ho parlarem amb més detall al final del capítol [6.3_Avaluacio_Algoritmes](6.3_Avaluacio_Algoritmes))\n",
    "- Tècniques de regularització: forçar el sistema a fer servir una versió més simple (eliminant característiques de les mostres que són irrellevants, reduint els nivells d'una arbre de decisió, etc.)\n",
    "- Parar les iteracions de l'algoritme abans de temps: quan fem servir algoritmes que aprenen de manera iterativa, és molt recomanable mesurar els resultats al final de cada iteració i detectar quan els resultats comencen a ser pitjors per parar a temps l'aprenentatge. Si deixem que continuï és molt probable que acabem generant overfitting.\n",
    "\n",
    "<table style=\"border:1px solid black\">\n",
    "    <tr><td><img src=\"Imatges/early-stopping-graphic.jpg\" size=500><br></td></tr>\n",
    "    <tr><td align=center size=500><i>Font: <a href=\"https://elitedatascience.com/overfitting-in-machine-learning\">Elite data science</a></i><br></td></tr>\n",
    "</table>\n",
    "\n",
    "I ara que ja tenim més clar què busquem en un sistema d'aprenentatge supervisat i què volem evitar, anem a estudiar alguns dels algoritmes de classificació més populars.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referències\n",
    "\n",
    "- Elite Data Science: Overfitting in Machine Learning: What It Is and How to Prevent It: [https://elitedatascience.com/overfitting-in-machine-learning](https://elitedatascience.com/overfitting-in-machine-learning)\n",
    "- EpicalSoft: Sobreajuste y subajuste (Overﬁtting and Underﬁtting): [http://epicalsoft.blogspot.com/2019/02/azure-machine-learning-sobreajuste-y.html](http://epicalsoft.blogspot.com/2019/02/azure-machine-learning-sobreajuste-y.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
