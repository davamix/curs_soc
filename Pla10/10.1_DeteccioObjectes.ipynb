{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.1 Detecció d'objectes amb Deep Learning\n",
    "\n",
    "Com hem pogut veure en els anteriors capítols el camp de la Visió per Computador pot tenir objectius molts variats depenent de l'aplicació real on vulguem aplicar-ho. Tot i que moltes vegades sembla que tot sigui el mateix respecte a detectar \"coses\" en imatges, és important diferenciar 4 funcionalitats ben diferenciades que sovint es confonen: classificació, localització d'objectes, detecció d'objectes i la segmentació.\n",
    "\n",
    "<table width=80%>\n",
    "    <tr>\n",
    "        <td style=\"border:1px solid black\">\n",
    "            <img src=\"Imatges/class-local-detec-segm.jpeg\">\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"border:1px solid black\" align=center >\n",
    "            Font imatge: <a href=\"https://medium.com/zylapp/review-of-deep-learning-algorithms-for-object-detection-c1f3d437b852\">Medium </a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "  \n",
    "  \n",
    "La **classificació** és la part de la visió per computador que classifica imatges segons el contingut. A partir d'un conjunt etiquetat d'aprenentatge, el sistema dedueix l'etiqueta per a noves imatges. Normalment es fan servir imatges centrades en l'objecte a classificar i, a més a més, aquest ocupa gran part de la imatge. Els exemples que hem fet servir per identificar dígits escrits a mà són un bon exemple de classificació. Actualment la classificació es considera un problema àmpliament resolt amb xarxes deep learning com GoogleNet o ResNet.\n",
    "\n",
    "La **localització d'objectes** en canvi, localitza zones d'interès de la imatge on es troba l'objecte que estem buscant. Típicament la sortida del sistema dibuixa un rectangle delimitador al voltant de l'objecte localitzat. Normalment els sistemes localitzadors busquen un sol objecte i, moltes vegades, són un pas intermedi d'un sistema més complet que precisa localitza un objecte per després processar-lo d'alguna manera. \n",
    "\n",
    "La **detecció d'objectes** és una combinació dels dos anteriors, localitza o troba *diversos* objectes *diferents* i classifica el tipus d'objectes que són. Per exemple, trobar els animals en una fotografia i etiquetar-los amb el tipus d'animal que són; o també els sistemes de conducció automàtica que el fan servir molt per localitzar i identificar perills (vianants creuant un carrer, altres cotxes envaint el nostre carril) o senyals de trànsit. Hem de tenir en compte que en cas de la classificació (i molts cops en el de la localització) només tenim un únic resultat, mentre que en la detecció d'objectes la sortida pot tenir un nombre variable de resultats. \n",
    "\n",
    "Finalment, la **segmentació** va un pas més enllà i a més a més de detectar un objecte, crea una màscara píxel per píxel de cadascun dels objectes detectats. Dins la segmentació encara trobem dos tipus ben diferenciats entre ells: la segmentació *semàntica* i la segmentació d'*instàncies*. En la segmentació semàntica s'analitza la imatge a nivell de píxels, no importa quin objecte representen, píxels semblants entre ells són categoritzats dins una segmentació concreta. En la segmentació per instàncies en canvi, primer existeix una detecció de l'objecte i posteriorment s'etiqueten els píxels de l'objecte detectat.\n",
    "\n",
    "<table width=80%>\n",
    "    <tr>\n",
    "        <td style=\"border:1px solid black\">\n",
    "            <img src=\"Imatges/segmentacio-semantica.png\">\n",
    "        </td>\n",
    "        <td style=\"border:1px solid black\">\n",
    "            <img src=\"Imatges/segmentacio-instancia.jpg\">\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"border:1px solid black\">\n",
    "            Segmentació semàntica: cada píxel és etiquetat.\n",
    "        </td>\n",
    "        <td style=\"border:1px solid black\">\n",
    "            Segmentació d'instàncies: s'etiqueten els píxels d'una mateixa instància detectada.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"border:1px solid black\">\n",
    "            Font imatge: <a href=\"http://sqlml.azurewebsites.net/2017/09/12/convolutional-neural-network/\">SQLML</a>\n",
    "        </td>\n",
    "        <td style=\"border:1px solid black\">\n",
    "            Font imatge: <a href=\"https://www.pyimagesearch.com/2018/11/26/instance-segmentation-with-opencv/\">PyImageSearch</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "La Visió per Computador ha anat evolucionant al llarg de la seva història segons les necessitats de les diferents indústries que la utilitzen i segons l'evolució dels algoritmes i el hardware que, cada cop més, permeten càlculs més complexes amb menys temps.\n",
    "\n",
    "Així, per exemple, en la indústria de l'automòbil es va començar per identificar de manera automàtica senyals de trànsit per ajudar a la conducció automàtica entrenant els sistemes amb imatges nítides i centrades en els senyals de trànsit (com es pot veure en la primera imatge de l'esquerra de la taula de sota), però a l'hora de la veritat, el que ens trobem en el món real i el que podem gravar des d'un cotxe en marxa quasi bé mai té imatges de senyals de trànsit com les fetes servir per classificar, sinó com una mínima part de tota la imatge que veiem (com es veu en el cas de la imatge de la dreta) i, per aquest motiu, es van començar a idear sistemes per localitzar primer, i detectar objectes després, que van permetre un gran salt endavant en aquests sistemes.\n",
    "\n",
    "<table width=80%>\n",
    "    <tr>\n",
    "        <td style=\"border:1px solid black\" align=center>\n",
    "            <img src=\"Imatges/classificacio-localitzacio-1.png\" ><br>\n",
    "        </td>\n",
    "        <td style=\"border:1px solid black\" align=center>\n",
    "            <img src=\"Imatges/classificacio-localitzacio-2.png\"><br>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"border:1px solid black\" width=300>\n",
    "            Imatge d'un senyal de trànsit per a classificació.\n",
    "        </td>\n",
    "        <td style=\"border:1px solid black\"  width=400>\n",
    "            Imatge del mateix senyal de trànsit en aplicacions en temps real (necessita localització i detecció del senyal).\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"border:1px solid black\" colspan=2>\n",
    "            Font imatge: <a href=\"https://www.datacamp.com/community/tutorials/object-detection-guide\">DataCamp</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "La detecció d'objectes en temps real és un dels camps més de moda dins la Visió per Computador i dins del Deep Learning, perquè és el que pot ajudar més en l'evolució de la tecnologia cap a sistemes autònoms com la conducció automàtica, la vigilància i seguretat a tots els nivells, i la sanitat entre d'altres. \n",
    "\n",
    "Tot i que el Deep Learning fa molt pocs anys que està entre nosaltres, ha tingut una evolució molt ràpida i fructífera, deixant un gran volum d'algoritmes i tècniques cada cop més eficients en la Visió per Computador. Concretament dins la detecció d'objectes, han aparegut diferents tècniques que podríem classificar dins d'un d'aquests dos grans grups:\n",
    "* Algoritmes de dues fases: Són aquells que en una primera fase localitzen possibles rectangles o regions interessants, i en la segona fase classifica aquestes zones utilitzant xarxes neuronals convolucionals. Exemples d'algoritmes de dues fases: R-CNN, Fast R-CNN, Faster R-CNN.\n",
    "* Algoritmes d'una fase: Són aquells que divideixen la imatge en propostes de regions, aquestes regions passen a una xarxa convolucional, i, finalment, aquestes regions es modifiquen i agrupen segons la predicció obtinguda. Alguns algoritmes d'una fase són SSD i YOLO.\n",
    "\n",
    "En aquest capítol farem un breu resum d'aquesta evolució i les principals diferències entre les principals tècniques de Deep Learning per a la detecció d'objectes, començant per l'Sliding Window i continuant pels algoritmes de dues i una fase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window\n",
    "\n",
    "<table width=100% >\n",
    "    <tr>\n",
    "        <td style=\"border:1px solid black;background-color:#F0F0FF\" >\n",
    "            <h4>IDEA: recórrer la imatge amb diferents mides de finestra, reescalar els patches i passar un classificador</h4>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"background:white\">\n",
    "            <img src=\"Imatges/sliding_window.jpg\">\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "#### Pseudo-codi:\n",
    "```\n",
    "    for window in windows\n",
    "        patch = get_patch(image, window)\n",
    "        resized_patch = adapt_size(patch)\n",
    "        results = detector(resized_patch)\n",
    "````\n",
    "\n",
    "Als principis de la detecció d'objectes, sobretot en detecció de cares, s'utilitzaven els *Sliding Windows* o finestres lliscants. La tècnica es basava en la utilització d'una finestra lliscant, una regió rectangular d'amplada i alçada fixades, que anava lliscant al llarg de tota la imatge original per trobar subfinestres, les quals, posteriorment, eren processades per un classificador d'imatges per determinar si la subfinestra tenia o no l'objecte buscat. \n",
    "\n",
    "Alguns exemples d'algoritmes que utilitzen finestres lliscants serien el Viola Jones Face Detector (que utilitza Haar Features i Boosting), o el HOG Pedestrian Detector (que utilitza descriptors HOG i un SVM lineal).\n",
    "\n",
    "Un dels principals problemes de la finestra lliscant era que la detecció de l'objecte depenia de la mida de la finestra i de la localització de l'objecte en la imatge. Si per exemple teníem un objecte més gran que la finestra lliscant, l'algoritme no podia detectar-lo. Per solucionar aquest problema van aparèixer les tècniques d'imatges piramidals, on s'aplicava la mateixa mida de la finestra lliscant a diferents escalats de la imatge original, assegurant així que en algun dels escalats l'objecte buscat cabria dins la finestra lliscant. La següent animació us mostra un exemple.\n",
    "\n",
    "<table width=400px>\n",
    "    <tr>\n",
    "        <td  style=\"border:1px solid black\">\n",
    "            <img src=\"Imatges/sliding-window-animated-sot.gif\" >\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"border:1px solid black\" >\n",
    "            Exemple de finestra lliscant i escalatge de la imatge original per a la detecció d'objectes.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"border:1px solid black\" align=center >\n",
    "            Font imatge: <a href=\"https://www.pyimagesearch.com/2015/03/23/sliding-windows-for-object-detection-with-python-and-opencv/\">PyImageSearch </a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "    \n",
    "Tot i que la tècnica acabava trobant objectes independentment de la seva localització i escalatge, el rendiment general del sistema era molt dolent perquè necessitava processar un gran nombre de subfinestres. I aquí és on van aparèixer els algoritmes de detecció d'objectes en dues fases que van millorar molt el rendiment.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
